{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sagemaker image classification training notebook\n",
    "Purpose of this notebook is to show end to end machine learning workflow\n",
    "1. Use label dataset created by Sagemaker GroundTruth. Then split the dataset into train and validation. \n",
    "2. Train the model using Sagemaker training container, \n",
    "3. Optimize model using Sagemaker Neo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Block below shows how to use GroundTruth labled dataset, then split data into training and validation\n",
    "### IMP: Plese change \"BUCKET =\" to you your S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import boto3\n",
    "import sagemaker\n",
    "import time\n",
    "\n",
    "BUCKET = 'yourbucket'\n",
    "EXP_NAME = 'dinodetector' # Any valid S3 prefix.\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.session.Session().region_name\n",
    "s3 = boto3.client('s3')\n",
    "bucket_region = s3.head_bucket(Bucket=BUCKET)['ResponseMetadata']['HTTPHeaders']['x-amz-bucket-region']\n",
    "assert bucket_region == region, \"You S3 bucket {} and this notebook need to be in the same region.\".format(BUCKET)\n",
    "\n",
    "# Enter your Sagemaker GroundTruth output manifests file location\n",
    "OUTPUT_MANIFEST ='s3://dino-dataset/output/dino-image-classification/manifests/output/output.manifest'\n",
    "# Download manifests file to local drive\n",
    "!aws s3 cp {OUTPUT_MANIFEST} 'output.manifest'\n",
    "\n",
    "with open('output.manifest', 'r') as f:\n",
    "    output = [json.loads(line) for line in f.readlines()]\n",
    "\n",
    "# Shuffle output in place.\n",
    "np.random.shuffle(output)\n",
    "    \n",
    "dataset_size = len(output)\n",
    "\n",
    "# Split dataset to 80/20 ration for training and validation\n",
    "\n",
    "train_test_split_index = round(dataset_size*0.8)\n",
    "\n",
    "train_data = output[:train_test_split_index]\n",
    "validation_data = output[train_test_split_index:]\n",
    "\n",
    "#Create training and validation files\n",
    "\n",
    "num_training_samples = 0\n",
    "with open('train.manifest', 'w') as f:\n",
    "    for line in train_data:\n",
    "        f.write(json.dumps(line))\n",
    "        f.write('\\n')\n",
    "        num_training_samples += 1\n",
    "    \n",
    "with open('validation.manifest', 'w') as f:\n",
    "    for line in validation_data:\n",
    "        f.write(json.dumps(line))\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload training and validation dataset to S3 bucket, so that this dataset can be used by Sagemaker Training jobs later\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "s3.upload_file('train.manifest',BUCKET, EXP_NAME + '/train.manifest')\n",
    "s3.upload_file('validation.manifest',BUCKET, EXP_NAME + '/validation.manifest')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Sagemaker training job. Change hyperparamerter per training needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create unique job name \n",
    "nn_job_name_prefix = 'sagemaker-nvidia-webinar-demo'\n",
    "timestamp = time.strftime('-%Y-%m-%d-%H-%M-%S', time.gmtime())\n",
    "nn_job_name = nn_job_name_prefix + timestamp\n",
    "num_classes = 6\n",
    "training_image = sagemaker.amazon.amazon_estimator.get_image_uri(boto3.Session().region_name, 'image-classification', repo_version='latest')\n",
    "\n",
    "training_params = \\\n",
    "{\n",
    "    \"AlgorithmSpecification\": {\n",
    "        \"TrainingImage\": training_image,\n",
    "        \"TrainingInputMode\": \"Pipe\"\n",
    "    },\n",
    "    \"RoleArn\": role,\n",
    "    \"OutputDataConfig\": {\n",
    "        \"S3OutputPath\": 's3://{}/{}/output/'.format(BUCKET, EXP_NAME)\n",
    "    },\n",
    "    \"ResourceConfig\": {\n",
    "        \"InstanceCount\": 1,   \n",
    "        \"InstanceType\": \"ml.p3.2xlarge\",\n",
    "        \"VolumeSizeInGB\": 50\n",
    "    },\n",
    "    \"TrainingJobName\": nn_job_name,\n",
    "    \"HyperParameters\": {\n",
    "        \"epochs\": \"30\",\n",
    "        \"image_shape\": \"3,224,224\",\n",
    "        \"learning_rate\": \"0.001\",\n",
    "        \"lr_scheduler_step\": \"10,20\",\n",
    "        \"mini_batch_size\": \"32\",\n",
    "        \"num_classes\": str(num_classes),\n",
    "        \"num_layers\": \"18\",\n",
    "        \"num_training_samples\": str(num_training_samples),\n",
    "        \"resize\": \"224\",\n",
    "        \"use_pretrained_model\": \"1\"\n",
    "    },\n",
    "    \"StoppingCondition\": {\n",
    "        \"MaxRuntimeInSeconds\": 86400\n",
    "    },\n",
    "    \"InputDataConfig\": [\n",
    "        {\n",
    "            \"ChannelName\": \"train\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataType\": \"AugmentedManifestFile\",\n",
    "                    \"S3Uri\": 's3://{}/{}/{}'.format(BUCKET, EXP_NAME, 'train.manifest'),\n",
    "                    \"S3DataDistributionType\": \"FullyReplicated\",\n",
    "                    \"AttributeNames\": [\"source-ref\",\"dino-image-classification\"]\n",
    "                }\n",
    "            },\n",
    "            \"ContentType\": \"application/x-recordio\",\n",
    "            \"RecordWrapperType\": \"RecordIO\",\n",
    "            \"CompressionType\": \"None\"\n",
    "        },\n",
    "        {\n",
    "            \"ChannelName\": \"validation\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataType\": \"AugmentedManifestFile\",\n",
    "                    \"S3Uri\": 's3://{}/{}/{}'.format(BUCKET, EXP_NAME, 'validation.manifest'),\n",
    "                    \"S3DataDistributionType\": \"FullyReplicated\",\n",
    "                    \"AttributeNames\": [\"source-ref\",\"dino-image-classification\"]\n",
    "                }\n",
    "            },\n",
    "            \"ContentType\": \"application/x-recordio\",\n",
    "            \"RecordWrapperType\": \"RecordIO\",\n",
    "            \"CompressionType\": \"None\"\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we will create the SageMaker training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_client = boto3.client('sagemaker')\n",
    "sagemaker_client.create_training_job(**training_params)\n",
    "\n",
    "# Confirm that the training job has started\n",
    "print('Transform job started')\n",
    "while(True):\n",
    "    status = sagemaker_client.describe_training_job(TrainingJobName=nn_job_name)['TrainingJobStatus']\n",
    "    if status == 'Completed':\n",
    "        print(\"Transform job ended with status: \" + status)\n",
    "        break\n",
    "    if status == 'Failed':\n",
    "        message = response['FailureReason']\n",
    "        print('Transform failed with the following error: {}'.format(message))\n",
    "        raise Exception('Transform job failed') \n",
    "    time.sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize the model specifically for the architecture\n",
    "Use Sagemaker Neo to optimize and compile model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = 's3://{}/{}/neo_output/'.format(BUCKET, EXP_NAME)\n",
    "model_path = 's3://{}/{}/output/{}/output/model.tar.gz'.format(BUCKET, EXP_NAME, nn_job_name)\n",
    "\n",
    "print(output_path)\n",
    "print(model_path)\n",
    "response = sagemaker_client.create_compilation_job(\n",
    "    CompilationJobName='sagemaker-nvidia-webinar',\n",
    "    RoleArn=role,\n",
    "    InputConfig={\n",
    "        'S3Uri': model_path,\n",
    "        'DataInputConfig': \"{'data':[1, 3, 224, 224]}\",\n",
    "        'Framework': 'MXNET'\n",
    "    },\n",
    "    OutputConfig={\n",
    "        'S3OutputLocation': output_path,\n",
    "        'TargetDevice': 'jetson_nano'\n",
    "    },\n",
    "    StoppingCondition={\n",
    "        'MaxRuntimeInSeconds': 900\n",
    "    }\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
